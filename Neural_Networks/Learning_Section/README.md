First let’s talk about what you should take away from all this. The idea is after this, you should have a basic understanding of how machine learning works at a high level. You do not have to be an expert in computer science or math, you don’t need to have advanced education, and you don’t have to work in tech. The way I think of machine learning is simply a program designed to mimic the most basic functions of how the human brain learns and trains itself to become more efficient over time. Think of how a child learns the alphabet. You spend time sounding out letters, looking at what each letter looks like, letting them know when they are right or wrong, and over time they eventually are able to easily distinguish letters. Machine learning works the same way, it is designed on something called a neural network to train itself on a specific outcome. Over time and with sufficient training data, a machine learning program would be able to distinguish letters of the alphabet. So with all that being said let’s get into the fun part, learning!

What is a neural network? In simple terms, it’s an imitation of how neurons are interconnected and communicate with each other via signals like the human brain. The neuron’s job is to receive and send messages from other neurons that ultimately lead to some sort of output. In the case of your brain, small signals are communicating from neuron to neuron that output to fingers typing on a keyboard. The network piece comes from how the neurons are arranged and intersect to build the outcome you are trying to achieve.

One of the ways I think of for visualizing a neural network, is by thinking of a system of filters that continues to filter information based on educated assessments of a certain piece of information until ultimately arriving at an answer. The next image is a high level drawing of a neural network. The top layer is considered the input layer, where depending on what is being evaluated will cause a neuron to fire. Depending on how that neuron interprets the input, it will then connect to another neuron in the next layer. From there it will continue to pass through each layer until it arrives at an output, which is one of the neurons in the bottom layer.

See Neural_Network_Drawing image.

To think about how this will be applied to a problem, we'll use the most common image recognition and learning method used in machine learning and that is recognizing numbers from hand drawn images maintained by the mnist database. Our good friends NIST (National Institute of Standards and Technology) have compiled thousands of handwritten images of numbers. The idea is some shape or form every image is unique in it's own right, whether that's a curve of a 2, a dash of a 7, or a connection of the top of a 4. Our brain has the ability to recognize which number is which based on the images and similarily we will use this data to train our program. 

The example we’ll use to help visualize this is how our brain actually recognizes a number. Most people can instantly recongize a number since we've become so attuned to it overtime and spent years practicing math. Well let's pretend we're new to this and just learning numbers for the first time like a kid. Well to do this we go through a series of trial and error to tackle number recognition by looking for common themes. Starting with the obvious themes such as a single straight line could be a one, then add a few dashes and it might be a 4, there could also be a distinctive trait such as two circles on top of each other indicating an 8. 

Initially when learning to numbers, a person may even start with a single number and continuously practice recognizing a single number so they can get really good at recognizing that number. Conversely, they could bucket them such as if there are loops such as a 6, 8, or 9. Well let’s say you take this approach and the first filter you use is numbers with loops. You’ll identify them hopefully relatively quickly and begin organizing them together by looking at each image and figuring out which ones have loops. From there you may start looking at the orientation of the image and determine if it's at the bottom indicating a 6, at the top indicating a 9, or both indicating an 8. Now let’s say you do this same execersize 10 times, 100 times, and then 1000 times! By the 1000th time you’ll probably be pretty good at recognizing those numbers because you’ve started to recognize certain patterns such as shape orientation, if there's a loop, and numbers of loops. Just looking at a number you may know immediately what it is and if not you can take a pretty good guess what it should be with a high percentage of success. Conceptually this is how a neural network works and is applied to machine learning.

Let's dissect the numbers example and how it actually works in a true neural network. We’ll start with what those filters we used are. Filters in a neural network are referred to as layers. A layer will have multiple neurons that essentially act as a number holder for an evaluation technique when assessed against all the other neurons in the layer it will provide relevant information to the other layers using some advanced math. The first layer would essentially be the initial input and the last layer would be for the output. When it comes to neural networks, you can add almost an infinite amount of layers in between, sometimes referred to as hidden layers. The layers in the middle all act as different filters that are connected to the layer in the front and back of it, each layer is intended to look for a very specific piece of information that will inform the other layers.

If we take a simple example from the numbers, let’s pretend we're looking for the number 8. One loop at the top and another loop at the bottom connecting the two loops. There’s going to be multiple layers that have each been assigned something specific to look for. For example there will be a layer with the neurons dedicated to filtering for rounded parts of a loop that would confirm a circle. Also a layer for if there's more than one loop. A layer dedicated to if there isn't two loops. A layer that looks for numbers with a straight line or lines that indicate a different number and so on and so on. From there by interacting with all these layers, the neurons will pass along information from layer to layer and voila! You have identified the number 8.

By now you may be thinking that you can probably add or tweak layers that will lead to more informed decisions and you’re right! We’ve covered at a high level what a neural network is and an example of how it works with respect to a number such as 8. Next we’ll cover how adjusting layers and the neurons within each layer can lead to more accurate and faster outputs. As you continue to learn about neural networks, you will better understand how they form the core foundation of machine learning. Up next weights and biases!

Now finally let's get to the code! This repo was created using git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git from Michael Nielsen's Neural Networks and Deep Learning ebook. 
This repo is intended to be used for learning purposes and any subsequent changes pushed will be for learning.

We start with the first understanding the data we'll be using to run this program. The data comes from MNIST (Modified National Institute of Standards and Technology Databse) and it is a large database of handwritten digits that are commonly used for training various image processing systems, such as this program. The reason this is important is because handwritten digits have variance to them depending on various factors such as: writing style, differences in how a number is written (i.e. a dash through the middle of a 7 or connecting the top of a 4 or not), and legibility. These can make numbers differ on paper, however our brain and eventually our program will be able to recognize what each number is.

The data set is 60,000 images, which we'll split into two parts. The first set is 50,000 images used to train the network and the second set is 10,000 images that will be used for validation. Last step is to make sure you have the Python library "Numpy" for the linear algebra parts.

The main part of the code starts with the "Network" class, which is how a neural network is represented. See "network.py line 19 for where the class is initialized. This Network class uses the list "sizes" to determine number of neurons in the respective layers. 

Weights and biases of the "Network" object are initialized randomly using the Numpy random.randn function to generate Gaussian distributions (Gaussian distribution refers to the probability distribution that is symmetric about the mean, aka the data closer to the mean the more frequent it happens. Think of a bell curve) with mean 0 and standard deviation 1. Note that weights and biases are stored as lists of Numpy matrices, so net.weights[1] stores the weights connecting the second and third layers since Python indexing starts at 1.

We define the sigmoid function at the bottom of the "network.py" file to reference. (The sigmoid function transforms the continuous real number into a range of ( 0 , 1 ) , so that the input value of the next layer is within a fixed range and the weight is more stable.) After that we create a feedforward method which acts as the input for the network. This is initialized by if "a" is input. 

Once we have the key parts in place, we create our first method of stochastic gradient descent. (LEAVE SECTION BLANK HERE TO REFER BACK TO EXPLANATION ALREADY PREPARED) Refer to the code in "network.py" line 44 for the implementation of SGD. We use variables epochs (An epoch is when all the training data is used at once and is defined as the total number of iterations of all the training data in one cycle for training the machine learning model. Another way to define an epoch is the number of passes a training dataset takes around an algorithm) and mini_batch_size, to set the number of epochs to train for and the size of the mini-batches to use when sampling. eta is the learning rate.

How the code executes, each epoch starts by randomly suffling the training data and then breaks it into mini-batches of appropriate size. For each mini_batch we then apply a single step of gradient descent. The "self.update_mini_batch(mini_batch, eta) updates the network weights and biases according to a single iteratino of gradient descent using only the training data in mini_batch. 

Finally in the update_mini_batch method, backpropagation is used to calculate the cost of gradient descent and inform our program how to best optimize based on the resuls. Backpropagation is invoked on line 69 by the line "delta_nabla_b, delta_nabla_w = self.backprop(x, y)" which ultimately updates the weights and biases.

Now you're finally ready to start the program! First you'll want to run the following commands: "import mnist_loader" and then "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()" this is to get the mnist data working. From there you'll set up the Network! Run "import network" and then "net = network.Network([784, 30, 10])" what this does is import the Python program and then set up the neurons. 784 refers to the pixels from a single MNIST image. In each image we have 28 pixels by 28 pixels. So the total is 784 pixels in a single MNIST image, with 30 hidden neurons, and then 10 possible outcomes 0 through 9. Last step will be to use the stochastic gradient descent to have our program learn from the MIST training data over 30 epochs, with a mini-batch size of 10 and a learning rate of n = 3.0. Run the command "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)" this will kick off the program and run the code to return our program. 

Ways to speed up the program could be to reduce the number of epochs, number of hidden neurons, or training data. This may not produce as accurate of a result, however that is the point of machine learning, to continuously train on data to improve performance. It is noted that this can be made to highly performant for production environments. 

By doing a few tests of increasing the number of hidden neurons to say 100, we should see improved accuracy. "net = network.Network([784, 100, 10])" and "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)" check the results. 

Now if we took a different approach and wanted to see how changes can decrease performance, we can change the learning rate to n = 0.001. Run "net = network.Network([784, 100, 10])" and then "net.SGD(training_data, 30, 10, 0.001, test_data= test_data)" and check the results. We should see a significant decrease in performance. 

You can play around with the number of neurons and learning rate to find the optimal accuracy, however it can be tricky at first.

This is where we wrap up our demo for today. Some things to consider are what we if we had a different problem than just solving which number of an image is. Some hypothetical examples could be solving a puzzle, figuring out if an image is a face, or if an image is a car? Think about what would be needed from a layers and corresponding neurons from there and then consider building your own model using what you learned here! Remember though for whatever you decide to do, you'll need a lot of training data!

Other considerations that should be thought about are what potential risks can come from machine learning and AI leveraging neural networks? What if training data is inaccurate or wrong? What if accuracy isn't at a high enough threshold and outputs wrong answers to the consumers / end users? What controls can be implemented to help mitigate some of the risks associated with these learning models? 

The flip side of risk considerations are what potential can be achieved leveraging these? Building models to train more accurate answers for customer support? Creating more robust programs that are highly performant? Try to think of a use case that could be aided by machine learning in your current role?

Last thing to think about is some of the "other" impacts we can consider. High energy consumption to support the machines powering these models and programs, how will that be achieved? Ethics of new students using AI / machine learning to solve problems or write for them? There's a lot to think about, but hopefully you can focus on the good! 